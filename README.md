# M5-Competion

This is the final file Version 1 out of 3 where in we built a bagged models for 4 different Learning Rate + 1 model with the poisson distribution ( with the d features amd hp filter fetaures). The idea of bagging is to reduce the overfitting and generates a solid outputs, we did the cross validation of marking the last 28 days as test and train the models on the rest.

Public LB : 0.471
Private LB : 0.574

Ranked 47th out of 5,000+ teams on Kaggle 
competition Name : https://www.kaggle.com/c/m5-forecasting-accuracy/

Team Name : Overdue Gold.
